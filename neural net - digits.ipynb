{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import cgt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from cgt import nn\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   5., ...,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,  10.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,  16.,   9.,   0.],\n",
       "       ..., \n",
       "       [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
       "       [  0.,   0.,   2., ...,  12.,   0.,   0.],\n",
       "       [  0.,   0.,  10., ...,  12.,   1.,   0.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1095eed10>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108fecf90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPYAAAD7CAYAAABZjGkWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109234f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray()\n",
    "plt.matshow(digits.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(digits.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we've had a little peek at our dataset, lets prep it for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "randinds = np.random.permutation(len(digits.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shuffle the values\n",
    "from sklearn.utils import shuffle\n",
    "data, targets = shuffle(digits.data, digits.target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scale the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(data)\n",
    "data_scaled = scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_scaled, targets, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1437, 64), (1437,))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep is done, time for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cgt.distributions import categorical\n",
    "\n",
    "def model(X, y):\n",
    "    # relu(W*x + b)\n",
    "    np.random.seed(0)\n",
    "    h1 = nn.rectify(nn.Affine(64, 512, weight_init=nn.IIDGaussian(std=.1))(X))\n",
    "    h2 = nn.rectify(nn.Affine(512, 512, weight_init=nn.IIDGaussian(std=.1))(h1))\n",
    "\n",
    "    # softmax probabilities\n",
    "    probs = nn.softmax(nn.Affine(512, 10)(h2))\n",
    "    \n",
    "    # our prediction is the highest probability\n",
    "    ypreds = cgt.argmax(probs, axis=1)\n",
    "        \n",
    "    acc = cgt.cast(cgt.equal(ypreds, y), cgt.floatX).mean()\n",
    "    cost = -categorical.loglik(y, probs).mean()\n",
    "    \n",
    "    return cost, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = cgt.matrix(name='X', fixed_shape=(None, 64))\n",
    "y = cgt.vector(name='y', dtype='i8')\n",
    "\n",
    "cost, acc = model(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've defined the cost and accuracy functions, time to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "# get all the weight parameters for our model\n",
    "params = nn.get_parameters(cost)\n",
    "# train via SGD, use 1e-3 as the learning rate\n",
    "updates = nn.sgd(cost, params, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "trainf = cgt.function(inputs=[X,y], outputs=[], updates=updates)\n",
    "cost_and_accf = cgt.function(inputs=[X,y], outputs=[cost,acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 took 0.172019004822, test cost = 2.20501685143, test accuracy = 0.524999976158\n",
      "Epoch 2 took 0.147954940796, test cost = 2.11127901077, test accuracy = 0.672222197056\n",
      "Epoch 3 took 0.153834104538, test cost = 2.02107143402, test accuracy = 0.730555534363\n",
      "Epoch 4 took 0.171836137772, test cost = 1.93480193615, test accuracy = 0.769444465637\n",
      "Epoch 5 took 0.165919065475, test cost = 1.85273849964, test accuracy = 0.783333361149\n",
      "Epoch 6 took 0.152409076691, test cost = 1.77495181561, test accuracy = 0.811111092567\n",
      "Epoch 7 took 0.152605772018, test cost = 1.70139038563, test accuracy = 0.819444417953\n",
      "Epoch 8 took 0.153925895691, test cost = 1.63193762302, test accuracy = 0.822222232819\n",
      "Epoch 9 took 0.15299487114, test cost = 1.56644046307, test accuracy = 0.830555558205\n",
      "Epoch 10 took 0.155354976654, test cost = 1.5047249794, test accuracy = 0.844444453716\n",
      "Epoch 11 took 0.163406848907, test cost = 1.44660675526, test accuracy = 0.852777779102\n",
      "Epoch 12 took 0.158044099808, test cost = 1.39189636707, test accuracy = 0.863888859749\n",
      "Epoch 13 took 0.153048038483, test cost = 1.34040379524, test accuracy = 0.866666674614\n",
      "Epoch 14 took 0.268903017044, test cost = 1.29194116592, test accuracy = 0.866666674614\n",
      "Epoch 15 took 0.195513010025, test cost = 1.24632537365, test accuracy = 0.87222224474\n",
      "Epoch 16 took 0.167809009552, test cost = 1.20337891579, test accuracy = 0.87777775526\n",
      "Epoch 17 took 0.160308837891, test cost = 1.16293108463, test accuracy = 0.880555570126\n",
      "Epoch 18 took 0.175884008408, test cost = 1.12482047081, test accuracy = 0.883333325386\n",
      "Epoch 19 took 0.175163984299, test cost = 1.08889222145, test accuracy = 0.886111140251\n",
      "Epoch 20 took 0.15843296051, test cost = 1.05500137806, test accuracy = 0.888888895512\n",
      "Epoch 21 took 0.169517993927, test cost = 1.02301156521, test accuracy = 0.897222220898\n",
      "Epoch 22 took 0.237608909607, test cost = 0.99279499054, test accuracy = 0.897222220898\n",
      "Epoch 23 took 0.199369907379, test cost = 0.964232325554, test accuracy = 0.897222220898\n",
      "Epoch 24 took 0.169267892838, test cost = 0.937210738659, test accuracy = 0.894444465637\n",
      "Epoch 25 took 0.162634134293, test cost = 0.911626338959, test accuracy = 0.897222220898\n",
      "Epoch 26 took 0.187767982483, test cost = 0.887383162975, test accuracy = 0.899999976158\n",
      "Epoch 27 took 0.176151037216, test cost = 0.864389777184, test accuracy = 0.902777791023\n",
      "Epoch 28 took 0.158120155334, test cost = 0.842563807964, test accuracy = 0.905555546284\n",
      "Epoch 29 took 0.160732030869, test cost = 0.821827352047, test accuracy = 0.908333361149\n",
      "Epoch 30 took 0.161874055862, test cost = 0.80210930109, test accuracy = 0.911111116409\n",
      "Epoch 31 took 0.158382892609, test cost = 0.783342838287, test accuracy = 0.911111116409\n",
      "Epoch 32 took 0.16233587265, test cost = 0.765466153622, test accuracy = 0.91388887167\n",
      "Epoch 33 took 0.161313056946, test cost = 0.748422086239, test accuracy = 0.916666686535\n",
      "Epoch 34 took 0.160571813583, test cost = 0.732157886028, test accuracy = 0.916666686535\n",
      "Epoch 35 took 0.161388158798, test cost = 0.716625630856, test accuracy = 0.916666686535\n",
      "Epoch 36 took 0.161670923233, test cost = 0.701779484749, test accuracy = 0.91388887167\n",
      "Epoch 37 took 0.177587032318, test cost = 0.687576293945, test accuracy = 0.916666686535\n",
      "Epoch 38 took 0.232905864716, test cost = 0.673977673054, test accuracy = 0.916666686535\n",
      "Epoch 39 took 0.195561885834, test cost = 0.660947620869, test accuracy = 0.919444441795\n",
      "Epoch 40 took 0.166347980499, test cost = 0.648452758789, test accuracy = 0.919444441795\n",
      "Epoch 41 took 0.164025068283, test cost = 0.636462330818, test accuracy = 0.919444441795\n",
      "Epoch 42 took 0.191772937775, test cost = 0.624947607517, test accuracy = 0.922222197056\n",
      "Epoch 43 took 0.172203063965, test cost = 0.613881647587, test accuracy = 0.922222197056\n",
      "Epoch 44 took 0.167120933533, test cost = 0.603238761425, test accuracy = 0.925000011921\n",
      "Epoch 45 took 0.171378850937, test cost = 0.592996060848, test accuracy = 0.925000011921\n",
      "Epoch 46 took 0.246295928955, test cost = 0.583131968975, test accuracy = 0.922222197056\n",
      "Epoch 47 took 0.190277814865, test cost = 0.573626458645, test accuracy = 0.922222197056\n",
      "Epoch 48 took 0.194919109344, test cost = 0.564460635185, test accuracy = 0.922222197056\n",
      "Epoch 49 took 0.173241853714, test cost = 0.555616557598, test accuracy = 0.922222197056\n",
      "Epoch 50 took 0.167927026749, test cost = 0.54707711935, test accuracy = 0.922222197056\n",
      "Epoch 51 took 0.198837041855, test cost = 0.538827240467, test accuracy = 0.922222197056\n",
      "Epoch 52 took 0.17116189003, test cost = 0.53085231781, test accuracy = 0.922222197056\n",
      "Epoch 53 took 0.169182062149, test cost = 0.523139059544, test accuracy = 0.922222197056\n",
      "Epoch 54 took 0.194655895233, test cost = 0.515675008297, test accuracy = 0.922222197056\n",
      "Epoch 55 took 0.200953006744, test cost = 0.508448719978, test accuracy = 0.922222197056\n",
      "Epoch 56 took 0.207528114319, test cost = 0.501448571682, test accuracy = 0.922222197056\n",
      "Epoch 57 took 0.200693130493, test cost = 0.494664013386, test accuracy = 0.922222197056\n",
      "Epoch 58 took 0.228640079498, test cost = 0.488085567951, test accuracy = 0.922222197056\n",
      "Epoch 59 took 0.170794963837, test cost = 0.481703519821, test accuracy = 0.925000011921\n",
      "Epoch 60 took 0.16282582283, test cost = 0.475509107113, test accuracy = 0.925000011921\n",
      "Epoch 61 took 0.171529054642, test cost = 0.469494462013, test accuracy = 0.927777767181\n",
      "Epoch 62 took 0.186758995056, test cost = 0.463651031256, test accuracy = 0.930555582047\n",
      "Epoch 63 took 0.166273117065, test cost = 0.457971692085, test accuracy = 0.930555582047\n",
      "Epoch 64 took 0.165516853333, test cost = 0.452449262142, test accuracy = 0.933333337307\n",
      "Epoch 65 took 0.225577831268, test cost = 0.447077095509, test accuracy = 0.933333337307\n",
      "Epoch 66 took 0.177847146988, test cost = 0.44184884429, test accuracy = 0.933333337307\n",
      "Epoch 67 took 0.198083162308, test cost = 0.436759442091, test accuracy = 0.933333337307\n",
      "Epoch 68 took 0.192444086075, test cost = 0.431802868843, test accuracy = 0.933333337307\n",
      "Epoch 69 took 0.248876094818, test cost = 0.426974326372, test accuracy = 0.933333337307\n",
      "Epoch 70 took 0.167292118073, test cost = 0.422268748283, test accuracy = 0.936111092567\n",
      "Epoch 71 took 0.164566040039, test cost = 0.41768103838, test accuracy = 0.936111092567\n",
      "Epoch 72 took 0.176681995392, test cost = 0.413206726313, test accuracy = 0.936111092567\n",
      "Epoch 73 took 0.193591117859, test cost = 0.40884155035, test accuracy = 0.938888907433\n",
      "Epoch 74 took 0.167150020599, test cost = 0.404581606388, test accuracy = 0.938888907433\n",
      "Epoch 75 took 0.166520118713, test cost = 0.400422841311, test accuracy = 0.938888907433\n",
      "Epoch 76 took 0.23548913002, test cost = 0.396361321211, test accuracy = 0.936111092567\n",
      "Epoch 77 took 0.184077978134, test cost = 0.392393708229, test accuracy = 0.938888907433\n",
      "Epoch 78 took 0.201885938644, test cost = 0.388516664505, test accuracy = 0.941666662693\n",
      "Epoch 79 took 0.171756982803, test cost = 0.384726941586, test accuracy = 0.941666662693\n",
      "Epoch 80 took 0.167394161224, test cost = 0.381021887064, test accuracy = 0.941666662693\n",
      "Epoch 81 took 0.191834926605, test cost = 0.377398520708, test accuracy = 0.941666662693\n",
      "Epoch 82 took 0.169857025146, test cost = 0.373853862286, test accuracy = 0.941666662693\n",
      "Epoch 83 took 0.165904998779, test cost = 0.37038564682, test accuracy = 0.941666662693\n",
      "Epoch 84 took 0.183192014694, test cost = 0.366991430521, test accuracy = 0.941666662693\n",
      "Epoch 85 took 0.208754062653, test cost = 0.363668441772, test accuracy = 0.941666662693\n",
      "Epoch 86 took 0.220321178436, test cost = 0.360414534807, test accuracy = 0.941666662693\n",
      "Epoch 87 took 0.175114870071, test cost = 0.357226997614, test accuracy = 0.941666662693\n",
      "Epoch 88 took 0.167252063751, test cost = 0.354103922844, test accuracy = 0.941666662693\n",
      "Epoch 89 took 0.192193984985, test cost = 0.351043522358, test accuracy = 0.941666662693\n",
      "Epoch 90 took 0.174372911453, test cost = 0.348043620586, test accuracy = 0.941666662693\n",
      "Epoch 91 took 0.166671991348, test cost = 0.345102459192, test accuracy = 0.944444417953\n",
      "Epoch 92 took 0.168147802353, test cost = 0.342217922211, test accuracy = 0.944444417953\n",
      "Epoch 93 took 0.165232181549, test cost = 0.339388877153, test accuracy = 0.944444417953\n",
      "Epoch 94 took 0.163515090942, test cost = 0.336613416672, test accuracy = 0.944444417953\n",
      "Epoch 95 took 0.164340019226, test cost = 0.333889514208, test accuracy = 0.944444417953\n",
      "Epoch 96 took 0.164921998978, test cost = 0.331215828657, test accuracy = 0.944444417953\n",
      "Epoch 97 took 0.162013053894, test cost = 0.32859069109, test accuracy = 0.944444417953\n",
      "Epoch 98 took 0.250111818314, test cost = 0.326013088226, test accuracy = 0.944444417953\n",
      "Epoch 99 took 0.19277715683, test cost = 0.323481678963, test accuracy = 0.944444417953\n",
      "Epoch 100 took 0.198880910873, test cost = 0.32099506259, test accuracy = 0.944444417953\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for i in xrange(epochs):\n",
    "    t1 = time.time()\n",
    "    for srt in xrange(0, X_train.shape[0], batch_size):\n",
    "        end = batch_size+srt\n",
    "        trainf(X_train[srt:end], y_train[srt:end])\n",
    "    elapsed = time.time() - t1\n",
    "    costval, accval = cost_and_accf(X_test, y_test)\n",
    "    print(\"Epoch {} took {}, test cost = {}, test accuracy = {}\".format(i+1, elapsed, costval, accval))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
